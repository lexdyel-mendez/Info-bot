{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lenght: 11070\n",
      "total words: 756\n",
      "['!!', '\".', '\"casa', '\"nanoaventuras', '#cahsi', '#colegiales', '#compscience', '#ece', '#hackathon', '#henaac30', '#hourofcode,', '#iap', '#icom', '#inel', '#outreach', '#research', '#uprm', '#utep.', '(b-392)', '(cra-e)', '(from', '(nsrec)', '-', '/', '13th', '14,', '15,', '16,', '16-20.', '17th', '18', '18th', '19th,', '20', '2014,', '2017', '2018', '2018.', '2019', '21', '26', '26th', '26th,', '2:00', '2pm,', '31', '3pm.', '3th', '7:30', '7th', '8,', '9028', '9am', '@adrianildefonso,', 'a', 'abilities', 'able', 'about', 'academia', 'academic', 'accenture', 'accomplishments', 'achievement', 'achievements.', 'aconer', 'acronym', 'activities', 'activity', 'activity.', 'adrian', 'advanced', 'advancement,', 'advisory', 'affiliates', 'after', 'age.', 'agrimensores', 'aguada,', 'agustin', 'aid', 'aim', 'algorithms', 'all', 'also', 'also,', 'alumni', 'always', 'an', 'and', 'andrade,', 'andrés', 'annual', 'another', 'ao', 'aponte,', 'apply', 'applying', 'appointed', 'appreciate', 'april', 'aquilino', 'are', 'are,', 'area', 'area!', 'areas', 'arecibo', 'arg', 'arms!', 'as', 'asociación', 'associate', 'association', 'assurance', 'at', 'atmospheric', 'auditorium', 'aurora', 'autonomous', 'available', 'award', 'award,', 'award.', 'awarded', 'be', 'bears', 'been', 'before', 'beginning', 'being', 'best', 'between', 'binary', 'biology', 'board', 'boston', 'both', 'boy', 'by', 'caban', 'cahsi', 'calderón', 'came', 'campus', 'can', 'candidates', 'capitular', 'capstone', 'career', 'careers', 'careers.', 'careers.#ece', 'carlos,', 'category', 'celebrate', 'celebrated', 'challenge', 'christmas', 'climbed', 'closed', 'coco,', 'colaborating', 'colegio', 'collaboration.', 'college.', 'collegiate', 'colón', 'committee', 'communication', 'communication,', 'community', 'company', 'competing', 'computation', 'computer', 'computers', 'concepts', 'conceptual', 'conclusion', 'conducting', 'conference', 'conference.', 'congratulate', 'congratulations', 'consulting', 'consultores', 'contact', 'continues', 'contratistas', 'contribution,', 'contributions', 'convene.', 'coop', 'corporation', 'counselor', 'counselors', 'course,”', 'couvertier', 'crew', 'cristian,', 'cruz-pol', 'current', 'cybersecurity', 'damaged', 'day', 'day.', 'de', 'deadline', 'december', 'decided', 'dedication', 'dedication,', 'del', 'demonstrating', 'department', 'department.', 'describe', 'design', 'desired', 'develop', 'developed', 'development', 'different', 'difficult', 'digital', 'dinner', 'director', 'directors,', 'disciplines', 'dissipating', 'do.', 'doctorate', 'documentary', 'doing', \"don't\", 'donation', 'dr.', 'drone', 'during', 'early', 'earthquake.', 'ece', 'eco-friendly', 'economic', 'economical', 'eduardo', 'education', 'effects', 'efficient', 'effort', 'effort!', 'effort,', 'electric', 'electrical', 'electricity.', 'electronic', 'electronics/hardware', 'electrons,', 'email.', 'emergency', 'emphasis.', 'en', 'encourage', 'energia', 'energy', 'engaged', 'engineering', 'engineering.', 'enrolling', 'ensure', 'eric', 'eugenio', 'event', 'event.', 'eventful', 'everyone', 'ex-colegial', 'excellence', 'excellence,', 'excellent', 'executive', 'experience', 'experiences', 'expert', 'explained', 'exposed', 'fabio', 'faculty', 'fall', 'february', 'fellows', 'fema', 'first', 'focus', 'for', 'foresight', 'forward', 'four', 'friday,', 'friends', 'from', 'full-', 'full-time', 'fundamentals', 'funded', 'further', 'future', 'gather', 'gave', 'generations', 'geographic', 'georgia', 'gil', 'girl', 'give', 'given', 'giving', 'gmis', 'gmis/henaac', 'go', 'goal', 'gonzalez', 'good', 'google', 'grad', 'grade', 'graduate', 'graduates', 'graduation', 'granted', 'great', 'greater', 'greatly', 'had', 'ham', 'harris', 'has', 'have', 'have,', 'having', 'he', 'held', 'help', 'helped', 'helping', 'helps', 'her', 'high', 'highly', 'him', 'his', 'hispanic', 'holiday', 'honor', 'hope', 'hosted', 'hosting', 'hostos', 'house', 'house.', 'how', 'hurricane', 'iap', 'iap.', 'icom', 'ieee', 'if', 'ildefonso', 'important', 'in', 'industrial', 'inel', 'info', 'information', 'information,', 'ingenieros', 'initiatives', 'inspire', 'institution', 'institution.', 'interact', 'interest', 'interested', 'internships', 'intro', 'introduced', 'involved', 'irizarry,', 'is', 'isaac', 'isidoro', 'island', 'island-wide', 'it', 'it!', 'its', 'january', 'jobs', 'josh', 'july', 'just', 'keep', 'know', 'knowledge', 'knows!', 'kristalys', 'laboratories', 'laboratory', 'laboratory,', 'last', 'lead', 'leadership', 'learn', 'learned', 'learning', 'led', 'lianne,', 'licensing', 'like', 'lives.', 'love', 'magnetism,', 'management', 'march', 'maria', 'maria.', 'marine', 'marrero', 'masters', 'may', 'mayaguez', 'mayagüez', 'meeting', 'meeting!', 'member', 'members', 'mendez', 'mentoring', 'miami’s', 'microgrid', 'miguel', 'minorities', 'miss', 'mixed-signal', 'month', 'more', 'most', 'motivated', 'much', 'multidisciplinary', 'musa', 'name.', 'nanogames', 'national', 'nayda', 'nayda’s', 'new', 'next', 'non-profit', 'not', 'notify', 'november', 'now', 'nuclear', 'numbers', 'observatory', 'observatory,', 'october', 'october,', 'october.', 'of', 'offered', 'offers', 'offers.', 'officially', 'on', 'one', 'open', 'oportunity', 'opportunities.', 'opportunity', 'options.', 'or', 'organization.', 'orientation', 'orienting', 'ortiz', 'our', 'out', 'outreach', 'outstanding', 'over', 'paper', 'participants', 'participate', 'participated', 'participating', 'participation', 'past', 'pedro', 'peers', 'people.', 'performance', 'performed', 'perspective', 'pilot', 'place', 'place!!', 'play', 'pleased', 'pm', 'possible.', 'poster', 'potential', 'pr', 'pr.', 'prep', 'prepares', 'presentation', 'presented', 'presenting', 'presents', \"president's\", 'prestigious', 'prior', 'problem', 'professional', 'professors', 'professors,', 'program', 'programs', 'programs.', 'project', 'projects', 'promote', 'prototyping', 'proud', 'provide', 'puerto', 'radiation', 'radio', 'rapid', 'rasp', 'rebuild', 'received', 'receiving', 'recent', 'reching', 'recognition.', 'recognized', 'recognizes', 'recommended', 'recruit', 'recruitment,', 'reflection', 'regulation', 'relating', 'remote', 'renewable', 'renovable', 'representation', 'representatives', 'research', 'research.', 'residence', 'resilience.', 'rest', 'results', 'reus', 'rico', 'rico,', 'rico.', 'rico”', 'rivas', 'rivera', 'room', 'rosenstiel', 'ruiz,', 's-210.', 's.u.', 'same', 'san', 'sandia', 'sandra', 'sandwiches', 'santiago', 'santiago.', 'scholarship', 'scholarship,', 'school', 'schools.', 'science', 'scientific,where', 'scouts', 'sebastian', 'second', 'section', 'secure,', 'see', 'semester', 'semester,', 'semester.', 'seminar', 'sensing', 'service', 'service.', 'session', 'several', 'sh-105.', 'sh-203.', 'share', 'short', 'show', 'showcase', 'showing', 'since', 'six', 'so', 'solar', 'solving', 'solving.', 'some', 'soon!', 'space', 'spanish)', 'speak', 'sponsored', 'sponsors.', 'spring', 'st.', 'staff', 'stage', 'star', 'step.', 'stood', 'student', 'student,', 'student.', 'students', 'students.', 'studying', 'success', 'such', 'sujeily,', 'summit', 'sunday', 'support.', 'supports', 'swe', 'system.', 'systems', 'systems.', 'talent', 'talked', 'taught', 'teach', 'teachers', 'team', 'teams', 'tech', 'tech.', 'technical', 'technologies.', 'technology', 'thank', 'thankful', 'thanks', 'that', 'the', 'their', 'them', 'there', 'therefore', 'these', 'they', 'this', 'thomas,', 'those', 'three', 'through', 'thursday,', 'tied', 'time', 'to', 'today', 'today,', 'tomorrow', 'training', 'trends', 'trip', 'two', 'undergraduate', 'understand', 'unique', 'universal', 'university', 'up', 'upr', 'uprm', 'uprm.', 'us', 'use', 'vacation!', 'velez', 'verde', 'very', 'vi.', 'via', 'visit', 'visited', 'visiting', 'voluntarily', 'volunteered', 'vélez', 'want', 'wanted', 'wants', 'was', 'we', 'wednesday', 'week', 'week!', 'week,', 'week.', 'welcome', 'welcomes', 'were', 'western', 'what', 'where', 'wherever', 'which', 'who', 'will', 'willing', 'winning', 'with', 'women', 'won', 'work', 'work!', 'work,', 'working', 'workshops', 'would', 'y', 'yamil', 'year-long', 'year.', 'yet', 'you', \"you're\", 'your', 'yrs', '“the', '\\ufeffthis']\n"
     ]
    }
   ],
   "source": [
    "text=(open(\"/Users/maria/github/Dataset.txt\", encoding = \"utf8\").read().lower())\n",
    "\n",
    "print('Total lenght:', len(text))\n",
    "chars = sorted(list(set(text.split())))\n",
    "print('total words:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3677\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'\\ufeff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-152fb4dd1f50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_chars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\ufeff'"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "        \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
